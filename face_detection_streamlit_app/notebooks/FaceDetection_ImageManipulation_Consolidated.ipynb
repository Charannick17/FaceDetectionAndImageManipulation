{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5365787e",
   "metadata": {},
   "source": [
    "# Face Detection and Image Manipulation\n",
    "Consolidated notebook created on 2025-08-19\n",
    "\n",
    "Features:\n",
    "- Real-time face detection using OpenCV and HaarCascade\n",
    "- Image manipulation (blur faces, apply filters, cropping)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ed8c35",
   "metadata": {},
   "source": [
    "## Imported from `filters.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c5930b",
   "metadata": {},
   "source": [
    "Filters \n",
    "\n",
    "based on the pixel we can increase or decrease the size of the pixel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d1def7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vid = cv2.VideoCapture(0)\n",
    "pixels = 20\n",
    "while 1:\n",
    "    _,img = vid.read()\n",
    "    cv2.flip(img,1)\n",
    "    filter_1 = img+(pixels*1.5)\n",
    "   \n",
    "    filter_1[filter_1<0]=0\n",
    "    filter_1[filter_1>255]=255\n",
    "    # if we are changing the pixels make sure to it is in int type\n",
    "    filter_1 = filter_1.astype(np.uint8)\n",
    "    \n",
    "    filter_2 = img+(pixels+5)\n",
    "    filter_2[filter_1<0]=0\n",
    "    filter_2[filter_1>255]=255\n",
    "    \n",
    "    filter_2 = filter_1.astype(np.uint8)\n",
    "    \n",
    "    cv2.imshow(\"org\",img)\n",
    "    cv2.imshow(\"fil_1\",filter_1)\n",
    "    cv2.imshow(\"fil_2\",filter_2)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b550e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decresease the image pixels\n",
    "import cv2\n",
    "import numpy as np\n",
    "vid = cv2.VideoCapture(0)\n",
    "pixels = 20\n",
    "while 1:\n",
    "    _,img = vid.read()\n",
    "    cv2.flip(img,1)\n",
    "    filter_1 = img-(pixels*1.5)\n",
    "   \n",
    "    filter_1[filter_1<0]=0\n",
    "    filter_1[filter_1>255]=255\n",
    "    # if we are changing the pixels make sure to it is in int type\n",
    "    filter_1 = filter_1.astype(np.uint8)\n",
    "    \n",
    "    filter_2 = img-(pixels+5)\n",
    "    filter_2[filter_1<0]=0\n",
    "    filter_2[filter_1>255]=255\n",
    "    \n",
    "    filter_2 = filter_1.astype(np.uint8)\n",
    "    \n",
    "    cv2.imshow(\"org\",img)\n",
    "    cv2.imshow(\"fil_1\",filter_1)\n",
    "    cv2.imshow(\"fil_2\",filter_2)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7348c827",
   "metadata": {},
   "source": [
    "adding blue lisht filter to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e92042",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape\n",
    "blue =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38c9366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "blues = []\n",
    "for i in range(480):\n",
    "    for j in range(640):\n",
    "        blues.append(blue)\n",
    "blues = np.array(blues,dtype = np.uint8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a746e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    _,img = vid.read()\n",
    "    cv2.flip(img,1)\n",
    "    blues = np.full(img.shape,[(255,0,0)],dtype = np.uint8)\n",
    "    yellow= np.full(img.shape,[(75,25,255)],dtype = np.uint8)\n",
    "    # add weighted is a function which combines the pixels of the color to the image\n",
    "    # it take addtitional three parameters -->aplha (float)->weight of first input\n",
    "    blue_fil=cv2.addWeighted(img,0.8,blues,0.05,1)\n",
    "    yelo_fil = cv2.addWeighted(img,0.9,yellow,0.15,1)\n",
    "    cv2.imshow(\"img\",img)\n",
    "    cv2.imshow(\"blue\",blue_fil)\n",
    "    cv2.imshow(\"yello\",yelo_fil)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8525e6",
   "metadata": {},
   "source": [
    "we can also merge the background image + original image \n",
    "--> we can need the  --> resize the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13da90c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_filter(source,dest,al,bet):\n",
    "    # reduce the size of the source of the file to destination\n",
    "    org = cv2.imread(source)\n",
    "    dest = cv2.imread(dest)\n",
    "    dest = cv2.resize(dest,(org.shape[1],org.shape[0]))\n",
    "    filter  = cv2.addWeighted(org,al,dest,bet,0)\n",
    "    cv2.imshow(\"orginal\",org)\n",
    "    cv2.imshow(\"filter\",filter)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bf41fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "src = \"charan.jpg\"\n",
    "file = \"back_ground_3.webp\"\n",
    "dest = os.path.join(\"background\",file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_filter(src,dest,0.9,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203d9891",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(dest)\n",
    "cv2.imshow(\"img\",src)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6ba8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcdbaea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14b4f591",
   "metadata": {},
   "source": [
    "## Imported from `image-detec.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d4e640",
   "metadata": {},
   "source": [
    "A Cascade Classifier in OpenCV is a machine learning-based approach for object detection. It is primarily used for detecting objects in images or video streams, such as faces, eyes, pedestrians, and other objects. The classifier is trained using a large number of positive and negative images, and it uses a cascade of simple classifiers (stages) to detect objects efficiently.\n",
    "\n",
    "Cascade Classifiers in OpenCV are powerful tools for object detection. They are efficient and can detect objects in real-time applications. By using pre-trained classifiers, you can quickly implement object detection in your projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63179ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "classifier= cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45131a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    _,img = vid.read()\n",
    "    faces=classifier.detectMultiScale(img,scaleFactor=1.1,minNeighbors=3,minSize=(30,30))\n",
    "    for x,y,w,h in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        cv2.putText(img,'Face Detected',(x-5,y-5),cv2.FONT_HERSHEY_SIMPLEX,1,(0,0,255),2)\n",
    "    cv2.imshow('face-detected',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf53e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb86c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    _,img = vid.read()\n",
    "    \n",
    "    mul = classifier.detectMultiScale2(img)\n",
    "    \n",
    "    print(mul)\n",
    "    if len(mul)<=3:\n",
    "        continue\n",
    "    for x,y,w,h in mul:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "       \n",
    "    \n",
    "    cv2.imshow('mul',img)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea66d22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5719ee35",
   "metadata": {},
   "source": [
    "croping image from detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcb1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58335e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    _,img = vid.read()\n",
    "    faces = classifier.detectMultiScale(img,1.1,3)\n",
    "    \n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        \n",
    "        crop =  img[y:y+h,x:x+w]\n",
    "        \n",
    "        cv2.imshow('detect-faces',img)\n",
    "        cv2.imshow('crop',crop)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c878bf7",
   "metadata": {},
   "source": [
    "fixed cropping using max_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c967127",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while 1:\n",
    "    _,img = vid.read()\n",
    "    faces = classifier.detectMultiScale(img,1.1,3)\n",
    "    \n",
    "    max_area=0\n",
    "    crop_max = None\n",
    "    for x,y,w,h in faces:\n",
    "        area = w*h\n",
    "        if area>max_area:\n",
    "            max_area=area\n",
    "            crop_max=(x,y,w,h)\n",
    "        \n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        \n",
    "        \n",
    "        crop =  img[y:y+h,x:x+w]\n",
    "        \n",
    "    cv2.imshow('detect-faces',img)\n",
    "    if crop_max:\n",
    "        x,y,w,h=crop_max\n",
    "        crop_face = img[y:y+w,x:x+h]\n",
    "        cv2.imshow('crop',crop_face)\n",
    "       \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd31fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0]\n",
    "img[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f136d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02993bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "size = img[y:y+h,x:x+w]\n",
    "plt.imshow(size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93235b39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60c0cc7e",
   "metadata": {},
   "source": [
    "## Imported from `img_detection.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f93b040",
   "metadata": {},
   "source": [
    "image detection using image masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8049b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "img =cv2.imread(\"cat_dog.webp\")\n",
    "lower= np.array([100,90,150])\n",
    "higher = np.array([180,240,224])\n",
    "mask = cv2.inRange(img,lower,higher)\n",
    "cv2.imshow(\"cat-dog\",img)\n",
    "cv2.imshow(\"mask\",mask)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145024eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "374e737e",
   "metadata": {},
   "source": [
    "## Imported from `img-video-blur-detect-face - Copy.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49a0686",
   "metadata": {},
   "source": [
    "face -detect and blur that position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10fa623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ae8a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    _,img = vid.read()\n",
    "    faces = classifier.detectMultiScale(img)\n",
    "    max_area=0\n",
    "    lar = None\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        area = w*h\n",
    "        if area>max_area:\n",
    "            max_area=area\n",
    "            lar = (x,y,w,h)\n",
    "    if  lar:\n",
    "        x,y,w,h = lar\n",
    "        # cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),5)\n",
    "        crop = img[y:y+h,x:x+w]\n",
    "        cv2.imshow(\"crop\",crop)\n",
    "        blur= cv2.blur(crop,(20,20))# blur\n",
    "        img[y:y+h,x:x+w]=blur\n",
    "        cv2.imshow(\"img\",img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb2fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    _,img = vid.read()\n",
    "    faces = classifier.detectMultiScale(img)\n",
    "    max_area=0\n",
    "    lar = None\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        area = w*h\n",
    "        if area>max_area:\n",
    "            max_area=area\n",
    "            lar = (x,y,w,h)\n",
    "    if  lar:\n",
    "        x,y,w,h = lar\n",
    "        # cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),5)\n",
    "        crop = img[y:y+h,x:x+w]\n",
    "        cv2.imshow(\"crop\",crop)\n",
    "        \n",
    "        blur= cv2.blur(crop,(20,20))# blur\n",
    "        color = np.full(blur.shape,(40,50,50),dtype = int)\n",
    "        img[y:y+h,x:x+w]=color\n",
    "        cv2.imshow(\"img\",img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c162612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8717f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "black = np.zeros(blur.shape,dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2814a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c6b63b70",
   "metadata": {},
   "source": [
    "Draw circle\n",
    "using mid point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ad4ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    _,img = vid.read()\n",
    "    faces = classifier.detectMultiScale(img)\n",
    "    max_area=0\n",
    "    lar = None\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        area = w*h\n",
    "        if area>max_area:\n",
    "            max_area=area\n",
    "            lar = (x,y,w,h)\n",
    "    if  lar:\n",
    "        x,y,w,h = lar\n",
    "        # cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),5)\n",
    "        cv2.circle(img,((x+(w//2)),(y+(y//2))),15,(0,0,255),-1)\n",
    "        # cv2.circle(img,((x+x+w)//2,(y+y+h)//2),100,(0,0,255),2)\n",
    "        crop = img[y:y+h,x:x+w]\n",
    "        cv2.imshow(\"crop\",crop)\n",
    "       \n",
    "        cv2.imshow(\"img\",img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25244b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"people.webp\")\n",
    "classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375c628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow(\"wind\",img)\n",
    "import os\n",
    "faces = classifier.detectMultiScale(img,1.1,5)\n",
    "c=0\n",
    "for x,y,w,h in faces:\n",
    "    crop = img[y:y+h,x:x+w]\n",
    "    fin_img = cv2.resize(crop,(300,300))\n",
    "    file = f\"people{c}.jpg\"\n",
    "    cv2.imshow(\"img\",fin_img)\n",
    "    file_path = os.path.join(\"people_classi\",file)\n",
    "    cv2.imwrite(file_path,fin_img)\n",
    "    c+=1\n",
    "    if c==5:\n",
    "        break\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7c93b2",
   "metadata": {},
   "source": [
    "# making own threeshould grey image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee4c189",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    _,img = vid.read()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # threeshold 1\n",
    "    gray_th1 = gray.copy()\n",
    "    # since it is a numpy array so we directly check\n",
    "    gray_th1[gray_th1>100]=255 #white\n",
    "    gray_th2 = gray.copy()\n",
    "    gray_th2[gray_th2<50]=10\n",
    "    # img[img<55]=0\n",
    "    cv2.imshow(\"img\",img)\n",
    "    cv2.imshow(\"gray\",gray)\n",
    "    cv2.imshow(\"gray-thresold\",gray_th1)\n",
    "    cv2.imshow(\"Gray_threshold_2\",gray_th2)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f680562f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "li = np.array([i for i in range(10)])\n",
    "li[li>5]=0\n",
    "print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4437e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3]\n",
    "k = [4,5,6]\n",
    "for i in l+k:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcf4e06",
   "metadata": {},
   "source": [
    "### threshold for color images\n",
    "\n",
    "### thresholding is nothing but adjusting the each pixel value based on the condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12fbcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cam = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    _,img = cam.read()\n",
    "    \n",
    "    key =cv2.waitKey(1)\n",
    "    # lower = np.array([150,150,152])\n",
    "    # upper = np.array([255,255,255])\n",
    "    # img[mask!=0]=[255,255,255]\n",
    "    mask = cv2.inRange(img,lower,upper)\n",
    "    lower = np.array([120,120,160])\n",
    "    upper = np.array([180,190,180])\n",
    "    mask = cv2.inRange(img,lower,upper)\n",
    "    img = cv2.blur(img,(4,4))\n",
    "    img[mask!=0] = [155,150,100]\n",
    "    \n",
    "    cv2.imshow(\"img\",img)\n",
    "    \n",
    "    if key==ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948e4259",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e807f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = (thre1[:,:,0]>100 | (thre1[:,:,1]>100) | (thre1[:,:,2]>100))\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dd29ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "thre1 = img.copy()\n",
    "mask = (thre1[:,:,0]>150 | (thre1[:,:,1]>150) | (thre1[:,:,2]>150))\n",
    "\n",
    "thre1[mask]=[0,255,100]\n",
    "cv2.imshow(\"thre1\",thre1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b23046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db5083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d71e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mat = np.array([[[12,3,5],[5,4,1],[3,4,5]],[[3,5,3],[4,3,1],[2,3,4]]])\n",
    "\n",
    "\n",
    "\n",
    "print(mat[:,1:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f7c931",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [[[12,3,5],[5,4,1],[3,4,5]],[[3,5,3],[4,3,1],[2,3,4]]]\n",
    "arr[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d891bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e013f52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b2d1734",
   "metadata": {},
   "source": [
    "## Imported from `img-video-blur-detect-face.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a43652",
   "metadata": {},
   "source": [
    "face -detect and blur that position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ae1f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64dc86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    _,img = vid.read()\n",
    "    faces = classifier.detectMultiScale(img)\n",
    "    max_area=0\n",
    "    lar = None\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        area = w*h\n",
    "        if area>max_area:\n",
    "            max_area=area\n",
    "            lar = (x,y,w,h)\n",
    "    if  lar:\n",
    "        x,y,w,h = lar\n",
    "        # cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),5)\n",
    "        crop = img[y:y+h,x:x+w]\n",
    "        cv2.imshow(\"crop\",crop)\n",
    "        blur= cv2.blur(crop,(20,20))# blur\n",
    "        img[y:y+h,x:x+w]=blur\n",
    "        cv2.imshow(\"img\",img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a87f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    _,img = vid.read()\n",
    "    faces = classifier.detectMultiScale(img)\n",
    "    max_area=0\n",
    "    lar = None\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        area = w*h\n",
    "        if area>max_area:\n",
    "            max_area=area\n",
    "            lar = (x,y,w,h)\n",
    "    if  lar:\n",
    "        x,y,w,h = lar\n",
    "        # cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),5)\n",
    "        crop = img[y:y+h,x:x+w]\n",
    "        cv2.imshow(\"crop\",crop)\n",
    "        \n",
    "        blur= cv2.blur(crop,(20,20))# blur\n",
    "        color = np.full(blur.shape,(40,50,50),dtype = int)\n",
    "        img[y:y+h,x:x+w]=color\n",
    "        cv2.imshow(\"img\",img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77695aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "blur.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea894f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a005734",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "black = np.zeros(blur.shape,dtype=int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f557a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90c499c9",
   "metadata": {},
   "source": [
    "Draw circle\n",
    "using mid point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143abd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    _,img = vid.read()\n",
    "    faces = classifier.detectMultiScale(img)\n",
    "    max_area=0\n",
    "    lar = None\n",
    "    \n",
    "    for x,y,w,h in faces:\n",
    "        area = w*h\n",
    "        if area>max_area:\n",
    "            max_area=area\n",
    "            lar = (x,y,w,h)\n",
    "    if  lar:\n",
    "        x,y,w,h = lar\n",
    "        # cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),5)\n",
    "        cv2.circle(img,((x+(w//2)),(y+(y//2))),15,(0,0,255),-1)\n",
    "        # cv2.circle(img,((x+x+w)//2,(y+y+h)//2),100,(0,0,255),2)\n",
    "        crop = img[y:y+h,x:x+w]\n",
    "        cv2.imshow(\"crop\",crop)\n",
    "       \n",
    "        cv2.imshow(\"img\",img)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c004a8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img = cv2.imread(\"people.webp\")\n",
    "classifier = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe18c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.imshow(\"wind\",img)\n",
    "import os\n",
    "faces = classifier.detectMultiScale(img,1.1,5)\n",
    "c=0\n",
    "for x,y,w,h in faces:\n",
    "    crop = img[y:y+h,x:x+w]\n",
    "    fin_img = cv2.resize(crop,(300,300))\n",
    "    file = f\"people{c}.jpg\"\n",
    "    cv2.imshow(\"img\",fin_img)\n",
    "    file_path = os.path.join(\"people_classi\",file)\n",
    "    cv2.imwrite(file_path,fin_img)\n",
    "    c+=1\n",
    "    if c==5:\n",
    "        break\n",
    "    \n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b53547",
   "metadata": {},
   "source": [
    "# making own threeshould grey image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784ab8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    _,img = vid.read()\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # threeshold 1\n",
    "    gray_th1 = gray.copy()\n",
    "    # since it is a numpy array so we directly check\n",
    "    gray_th1[gray_th1>100]=255 #white\n",
    "    gray_th2 = gray.copy()\n",
    "    gray_th2[gray_th2<50]=10\n",
    "    # img[img<55]=0\n",
    "    cv2.imshow(\"img\",img)\n",
    "    cv2.imshow(\"gray\",gray)\n",
    "    cv2.imshow(\"gray-thresold\",gray_th1)\n",
    "    cv2.imshow(\"Gray_threshold_2\",gray_th2)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key==ord('q'):\n",
    "        break\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4744444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "li = np.array([i for i in range(10)])\n",
    "li[li>5]=0\n",
    "print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7b1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [1,2,3]\n",
    "k = [4,5,6]\n",
    "for i in l+k:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70258e63",
   "metadata": {},
   "source": [
    "### threshold for color images\n",
    "\n",
    "### thresholding is nothing but adjusting the each pixel value based on the condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc67754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "cam = cv2.VideoCapture(0)\n",
    "while 1:\n",
    "    _,img = cam.read()\n",
    "    \n",
    "    key =cv2.waitKey(1)\n",
    "    # lower = np.array([150,150,152])\n",
    "    # upper = np.array([255,255,255])\n",
    "    # img[mask!=0]=[255,255,255]\n",
    "    mask = cv2.inRange(img,lower,upper)\n",
    "    lower = np.array([120,120,160])\n",
    "    upper = np.array([180,190,180])\n",
    "    mask = cv2.inRange(img,lower,upper)\n",
    "    img = cv2.blur(img,(4,4))\n",
    "    img[mask!=0] = [155,150,100]\n",
    "    \n",
    "    cv2.imshow(\"img\",img)\n",
    "    \n",
    "    if key==ord('q'):\n",
    "        break\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897f36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d124785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask = (thre1[:,:,0]>100 | (thre1[:,:,1]>100) | (thre1[:,:,2]>100))\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c9509",
   "metadata": {},
   "outputs": [],
   "source": [
    "thre1 = img.copy()\n",
    "mask = (thre1[:,:,0]>150 | (thre1[:,:,1]>150) | (thre1[:,:,2]>150))\n",
    "\n",
    "thre1[mask]=[0,255,100]\n",
    "cv2.imshow(\"thre1\",thre1)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36f3192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4266222c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f8df90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "mat = np.array([[[12,3,5],[5,4,1],[3,4,5]],[[3,5,3],[4,3,1],[2,3,4]]])\n",
    "\n",
    "\n",
    "\n",
    "print(mat[:,1:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f81e89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = [[[12,3,5],[5,4,1],[3,4,5]],[[3,5,3],[4,3,1],[2,3,4]]]\n",
    "arr[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205392df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a3ac08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
